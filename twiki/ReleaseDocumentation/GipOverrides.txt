%META:TOPICINFO{author="KyleGross" date="1480625620" format="1.1" version="1.11"}%
%META:TOPICPARENT{name="GenericInformationProvider"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%DOC_STATUS_TABLE%
%TOC{depth="2"}%

---++ Adding site specific attributes to GIP output that are not included in Glue schema
%NOTE% This feature is only available in OSG v1.0 (June 11, 2008).

The GIP uses the Glue Schema to publish information about the site; however, the Glue Schema constraints GIP to only publish a fixed set of attributes.

The problem of adding custom information to our sites keeps arising under different circumstances. For example
   1 FNAL uses a grid to fabric requirement forwarding: how to set batch system constraints to submit jobs to a subcluster specified via grid requirements; 
   1 MPI parameters: how to give applications information about MPI library location, version, etc. 

Extending the Glue schema is an option, but the process is time consuming and requires coordination among various Grids. Without this coordination, OSG cannot extend this schema for its own purposes because it breaks interoperability with LCG.

Our solution to this problem is giving a mechanism for administrators to extend the schema published by GIP and filter out these extra attributes before they are published to BDII. This way, the schema available in BDII is still compliant with the Glue Schema and interoperability is maintained. At the same time, other information systems, such as ReSS, will be able to publish the extra custom attributes for the OSG users.

---+++ How do I get my GIP to publish non Glue Schema attributes?
 The procedure in this section is for adding new attributes to existing DNs. 
%NOTE% If you want to add a completely new DN, follow instructions in case 2 ("adding new DNs") in section "[[GipOverrides#Overwriting_attributes_published][Overwriting attributes published by GIP]]" below. 
   1 Add the extra attributes to appropriate GIP templates file. There are two sets of templates for GIP 1.0, and both must be edited. Look in $VDT_LOCATION/gip/templates and $VDT_LOCATION/templates/compat. In the upcoming GIP 1.0.2 bugfix release (slated for September 2008), you do not need to edit *any* templates. Just add it to alter-attributes.conf, as documented in the next step. The only restrictions on the newly added attributes are: 
      * The attribute should not start with the keyword 'Glue' 
      * It should not be called 'dn' 
      * It should not be called 'objectClass' 
   1 Set the value that you want to publish . This can be done in any of the following ways: 
      * Add an entry in the alter-attributes.conf file to change this value. (see how to do this in case 1 in section "[[GipOverrides#Overwriting_attributes_published][Overwriting attributes published by GIP]]" below). 
      * You can set static attribute value in the template file (step 1) 
      * Write a more full-fledged plugin, if the values you need to publish change dynamically. (GIP plugins and providers included in the GIP can be found in $VDT_LOCATION/gip/libexec/) 
   1 Run $VDT_LOCATION/vdt/setup/configure_gip (if you don't, the values will get few hours to get updated, since configure_gip gets run every few hours) 
   1 Run $VDT_LOCATION/gip/libexec/osg-info-wrapper to see the GIP output. 

---++++!! An Example
 Let us say you want to advertise MPI attributes (!MPIInterconnect, !MPICompilerLocation, MPIVendor) that are associated with a particular subcluster. To accomplish this you would do the following 
   * NOTE: In the upcoming GIP 1.0.2 bugfix release (slated for September 2008), you do not need to edit *any* templates. Just add it to alter-attributes.conf, as documented in the next step. For previous version, you must first modify the $VDT_LOCATION/gip/etc/GlueCluster.template and add the following entry within the subcluster region <verbatim>MPIInterconnect:
MPIVendor:
MPICompilerLocation: </verbatim> 
   * Next update $VDT_LOCATION/gip/etc/alter-attributes.conf to add the values associated with the cluster. <pre>dn: GlueSubClusterUniqueID=mysubcluster1.univ.edu, GlueClusterUniqueID=mycluster.univ.edu,mds-vo-name=local,o=grid<br />MPIVendor: MPICH<br />MPIInterconnect: Infiniband<br />MPICompilerLocation: /usr/local/mpi/mpi-compiler<br /><br />dn: GlueSubClusterUniqueID=mysubcluster2.univ.edu, GlueClusterUniqueID=mycluster.univ.edu,mds-vo-name=local,o=grid<br />MPIVendor: OpenMPI<br />MPIInterconnect: GigE<br />MPICompilerLocation: /sw/mpi/mpi-compiler </pre> 
   * Next run $VDT_LOCATION/vdt/setup/configure_gip and verify the newly added values are getting propagated by checking the output of $VDT_LOCATION/gip/libexec/osg-info-wrapper, 
---++ Overwriting attributes published by GIP

Since =configure_gip= runs as a cron jobs site admins who used to manually update some values can no longer directly update the ldif files. Instead we have added two files: =alter-attributes.conf= and =add-attributes.conf=. These files are to be located at =$VDT_LOCATION/gip/etc/=. They exploit the plugin and provider mechanism of OSG-GIP to give admins the highest priority to set any values. This approach is particularly useful in case you want to add new dn's. This also makes it easier to preserve changes across software updates.

%IMPORTANT% If you want to alter or add multiple DNs, remember to have two new-line characters between the DNs.

%IMPORTANT% Each override entry has to begin with the line <br /> =dn: Glue...UniqueId=...,...= %BR% This line is crucial to identify where the information you are putting should go. This can be thought of as an hash key, telling GIP what exact attribute should be altered. ([[http://tille.garrels.be/training/ldap/ch01s03.html][More about the ldif format...]])

---++++!! Typical use-case for overwriting attributes

---+++++!! Case 1: Altering values published for attributes for existing DNs

This allows the site admin to alter the values that are being published.

Example 1: Changing the values associated with !GlueHostNetworkAdapterInboundIP and !GlueHostNetworkAdapterOutboundIP . By default these attributes are initialized as follows:

<verbatim>
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE 
</verbatim>

Let us say for example you want to specify that you Worker nodes don't have network access. This can be done as follows: 

Edit/Create =$VDT_LOCATION/gip/etc/alter-attributes.conf=, and add lines similar to the example below (You need to change 'grow-test1.its.uiowa.edu' to your sites 'FQDN' and the 'osg' in 'jobmanager-condor-osg' to the appropriate VO)

<verbatim>
dn: GlueSubClusterUniqueID=grow-test1.its.uiowa.edu, GlueClusterUniqueID=grow-test1.its.uiowa.edu,mds-vo-name=local,o=grid
GlueHostNetworkAdapterOutboundIP: FALSE 
</verbatim>

Example 2: If you want to state that you have inbound access to your worker node, as well as change the Operating System value being published for this SubCluster. In this case you will again edit =$VDT_LOCATION/gip/etc/alter-attributes.conf= and add the lines as you see in the illustration below.

<verbatim>
dn: GlueSubClusterUniqueID=grow-test1.its.uiowa.edu, GlueClusterUniqueID=grow-test1.its.uiowa.edu,mds-vo-name=local,o=grid
GlueHostNetworkAdapterInboundIP: TRUE
GlueHostOperatingSystemName: My OS
GlueHostOperatingSystemRelease: MY OS RELEASE
GlueHostOperatingSystemVersion: MY-OS_V1 
</verbatim>

---+++++!! Case 2: Adding new DNs
 This gives site admin a mechanism to publish new information that are not being published by GIP. This will be most useful if site admins want to publish multiple subclusters.

%NOTE% This is an addition to existing !DNs which are already being published.

Example: Let us say you already have one !SubCluster being published by !GIP and you would like to associate two more sub-clusters (with different architecture, !OS) within the same cluster. Let these be identified by unique IDs grow-subcluster1.its.uiowa.edu and grow-subcluster2.its.uiowa.edu, and let them be associated with the cluster grow-cluster.its.uiowa.edu. Then in order to publish these two new !SubClusters, we will add the following entries to the =$VDT_LOCATION/gip/etc/add-attributes.conf= file.

%IMPORTANT% It is important to get the !UniqueIDs correct since LDAP used them to form its directory structure

%STARTMore%
<verbatim>
dn: GlueSubClusterUniqueID=grow-subcluster1.its.uiowa.edu, GlueClusterUniqueID=grow-cluster.its.uiowa.edu,mds-vo-name=local,o=grid
objectClass: GlueClusterTop
objectClass: GlueSubCluster
objectClass: GlueSchemaVersion
objectClass: GlueHostApplicationSoftware
objectClass: GlueHostArchitecture
objectClass: GlueHostBenchmark
objectClass: GlueHostMainMemory
objectClass: GlueHostNetworkAdapter
objectClass: GlueHostOperatingSystem
objectClass: GlueHostProcessor
objectClass: GlueInformationService
objectClass: GlueKey
GlueChunkKey: GlueClusterUniqueID=grow-cluster.its.uiowa.edu
GlueHostApplicationSoftwareRunTimeEnvironment: OSG-ITB-0.5.2
GlueHostArchitectureSMPSize: 2
GlueHostBenchmarkSF00: 380
GlueHostBenchmarkSI00: 400
GlueHostMainMemoryRAMSize: 512
GlueHostMainMemoryVirtualSize: 1024
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE
GlueHostOperatingSystemName: MAC OS X
GlueHostOperatingSystemRelease: 10.4.6
GlueHostOperatingSystemVersion: Unknown
GlueHostProcessorClockSpeed: 1000
GlueHostProcessorModel: Mac
GlueHostProcessorVendor: Mac
GlueSubClusterName: grow-subcluster1.its.uiowa.edu
GlueSubClusterUniqueID: grow-subcluster1.its.uiowa.edu
GlueSubClusterPhysicalCPUs: 1
GlueSubClusterLogicalCPUs: 2
GlueSubClusterTmpDir: /grow/data-local/data
GlueSubClusterWNTmpDir: /tmp
GlueInformationServiceURL: ldap://grow-test1.its.uiowa.edu:2135/mds-vo-name=local,o=grid
GlueSchemaVersionMajor: 1
GlueSchemaVersionMinor: 2

dn: GlueSubClusterUniqueID=grow-subcluster2.its.uiowa.edu, GlueClusterUniqueID=grow-cluster.its.uiowa.edu,mds-vo-name=local,o=grid
objectClass: GlueClusterTop
objectClass: GlueSubCluster
objectClass: GlueSchemaVersion
objectClass: GlueHostApplicationSoftware
objectClass: GlueHostArchitecture
objectClass: GlueHostBenchmark
objectClass: GlueHostMainMemory
objectClass: GlueHostNetworkAdapter
objectClass: GlueHostOperatingSystem
objectClass: GlueHostProcessor
objectClass: GlueInformationService
objectClass: GlueKey
GlueChunkKey: GlueClusterUniqueID=grow-cluster.its.uiowa.edu
GlueHostApplicationSoftwareRunTimeEnvironment: OSG-ITB-0.5.2
GlueHostArchitectureSMPSize: 2
GlueHostBenchmarkSF00: 380
GlueHostBenchmarkSI00: 400
GlueHostMainMemoryRAMSize: 512
GlueHostMainMemoryVirtualSize: 1024
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE
GlueHostOperatingSystemName: RedHat Generic
GlueHostOperatingSystemRelease: RedHat Unknown
GlueHostOperatingSystemVersion: Unknown
GlueHostProcessorClockSpeed: 1000
GlueHostProcessorModel: Intel(R) Pentium(R) D CPU 3.00GHz
GlueHostProcessorVendor: GenuineIntel
GlueSubClusterName: grow-subcluster2.its.uiowa.edu
GlueSubClusterUniqueID: grow-subcluster2.its.uiowa.edu
GlueSubClusterPhysicalCPUs: 1
GlueSubClusterLogicalCPUs: 2
GlueSubClusterTmpDir: /grow/data-local/data
GlueSubClusterWNTmpDir: /tmp
GlueInformationServiceURL: ldap://grow-test1.its.uiowa.edu:2135/mds-vo-name=local,o=grid
GlueSchemaVersionMajor: 1
GlueSchemaVersionMinor: 2 </verbatim> %ENDMore%

---+++!! Adding site defined constraints to custom configure condor status commands
 In GIP, it is now possible to add "--constraint" options to condor commands from GIP, to allow for custom configuration of GIP values. This constraint gets passed on to condor_status requests made by the GIP dynamic plugins. The use case for this came from BNL, where they had the nodes being shared between both the ITB and production cluster and they specify constraints in their condor class ads, as to how many nodes are available in each case. By default GIP dynamic plugins get the information about free and total cpus by executing a "condor_status" command without any parameter. So GIP was publishing incorrect information that could potentially affect !ReSS. In order to address this use case we added new options that can be added to the [CONDOR] section of the config.ini file. 

In order to enable this functionality (add administrator defined "--constraint" option to condor_status queries made by osg-info-dynamic-condor) add the following lines.

For a condor_status constraint:
<verbatim>
status_constraint = Your_constraint
</verbatim>

For a condor_q constraint:
<verbatim>
jobs_constraint = Your_constraint
</verbatim>

An example constraint
<verbatim>
jobs_constraint = CPU_Type == \"osgitb\"
</verbatim>

%STOPINCLUDE% 

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = AnthonyTiradani

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = ComputeElement

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation

  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %NO%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%


 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = GabrieleGarzoglio
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


############################################################################################################
-->