---+ Gratia Troubleshooting Guide

%TOC{depth="3"}%


---++ About This Guide

Gratia is OSG software that gathers resource usage data (e.g., number and duration of jobs run, number and size of file transfers) from a site and ultimately transmits it to a central OSG storage system for reporting. The individual software tools that gather data are called _Gratia probes_, and the most common type of problem with Gratia at a site is that one or more probes stop sending data&nbsp;&mdash; either because they fail to run, fail to collect data properly, or fail to send collected data. If you are running an optional _Gratia Collector_ at your site to collect site probe data and forward it to the central OSG system, it may have problems, too.

Use this document to troubleshoot common problems with Gratia at your site, especially Gratia probes that have stopped sending data.


---++ General Troubleshooting Items

Before continuing with Gratia-specific troubleshooting, ensure that your Gratia packages are up-to-date and unmodified.

---+++ Making sure packages are up-to-date

A common source of software problems is out-of-date software. Make sure that your Gratia RPMs are up-to-date:

<pre class="rootscreen">%UCL_PROMPT_ROOT% yum update "gratia-*"</pre>

If you just want to see the packages to update, but do not want to perform the update now, answer =N= at the prompt.

---+++ Verifying package contents

If the contents of your Gratia packages have changed since they were installed, the software may not work properly. Verify the contents of your packages (ignoring changes to configuration files):

<pre class="screen">%UCL_PROMPT% rpm -qa | grep ^gratia | xargs rpm -q --verify | awk '$2 != "c"'</pre>

If the verification command returns output, this means that your package contents have changed. To fix this, you can reinstall the packages:

<pre class="rootscreen">%UCL_PROMPT_ROOT% yum reinstall "gratia-*"</pre>

%NOTE% The =reinstall= command may place original versions of configuration files alongside the versions that you have modified. If this is the case, the reinstall command will notify you that the original versions will have an =.rpmnew= suffix. Compare any =.rpmnew= files to their corresponding configuration files and decide whether to merge contents.


---++ Gratia Troubleshooting Items

Use this section to identify and try to fix common Gratia software problems at your site.

First, it may be helpful to increase the logging level in your =/etc/gratia/%RED%PROBE-NAME%ENDCOLOR%/ProbeConfig= files (either specific ones that have problems, or all of them to catch a broad range of problems):

<pre class="file">LogLevel="<span style="background-color: #FFCCFF;">5</span>"</pre>

After troubleshooting, be sure to reset the log level:

<pre class="file">LogLevel="<span style="background-color: #FFCCFF;">2</span>"</pre>

---+++ One or more Gratia probes are not sending data

By far, the most commonly observed problem with Gratia at a site is that one or more probes stop sending data. There are several possible root causes for this problem, so check through all of the following subsections as needed.

---++++ Stopped probes #1: Are Gratia probes enabled to run?

Each Gratia probe runs periodically from a =cron= entry, and there is a service to manage the overall status of the Gratia probe system. At least one probe plus the service itself must be enabled for anything to run. Use the following process to check whether the Gratia probe system and individual probes are enabled to run.

   1. Verify that Gratia probes are enabled to run in general:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% /sbin/service gratia-probes-cron status</pre>\
      <p>The output shows whether =gratia probes cron= is =enabled= or =disabled=.</p>
   1. If =gratia probes cron is disabled=, then enable the Gratia probes =cron= system in general:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% /sbin/service gratia-probes-cron start</pre>
   1. Ensure that one or more Gratia probes are enabled:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% grep EnableProbe /etc/gratia/*/ProbeConfig</pre>\
      <p>For each probe path, =EnableProbe="1"= means that the probe is enabled and =EnableProbe="0"= means that it is disabled.</p>

Ensure that =EnableProbe="1"= in each of your =ProbeConfig= files:\
       <pre class="rootscreen">%UCL_PROMPT_ROOT% grep EnableProbe /etc/gratia/*/ProbeConfig
/etc/gratia/condor/ProbeConfig:    EnableProbe="1"</pre>

*If Gratia is enabled*, running the command specified in =/etc/cron.d/gratia-probe*.cron= may provide insight into the failures. The following steps use =gratia-probe-condor= as an example but apply to all Gratia probes:

   1. Here are the contents of =/etc/cron.d/gratia-probe-condor.cron=, with the relevant command highlighted (dropping the =-s= option):\
   <pre class="file">0,15,30,45 * * * * root <span style="background-color: #FFCCFF;">/usr/share/gratia/common/cron_check  /etc/gratia/condor/ProbeConfig && /usr/share/gratia/condor/condor_meter</span> -s 900</pre>
   1. Run the command from the previous step:\
   <pre class="rootscreen">%UCL_PROMPT_ROOT% /usr/share/gratia/common/cron_check  /etc/gratia/condor/ProbeConfig && /usr/share/gratia/condor/condor_meter</pre>

The output of the above command determines your next actions:

   * *If you don't see any output and a log file is created*, check if that solved your original problem. If not, continue with the rest of the troubleshooting document.
   * *If you see a =Parse error in /etc/gratia/condor/ProbeConfig...= message,* there is an error in your configuration and you will need to verify the correctness of its XML syntax.
   * *If you see other errors,* continue with the rest of the troubleshooting document.
   * *If you don't see any output and a log file is NOT created*, [[#OsgSupport][contact us for help]]

---+++ Does the !SiteName name match the resource in OIM?

The value of =SiteName= in your [[Documentation.Release3/InstallGratia_DRAFT#FilesAndDirs][ProbeConfig]] must match the resource in OIM. Here is an example of a site topology from [[http://oim.opensciencegrid.org][OIM]]:

<img src="%ATTACHURLPATH%/oim_topology.png"/> 

In the above example, =WIPAC= is the site, =IceCube= is the resource group, =NPX= is the CE's resource name. To set =SiteName= properly, choose one of the following options:

   * *If you are configuring a CE,* edit the value of =resource= in =/etc/osg/config.d/40-siteinfo.ini= and run =osg-configure=:\
   <pre class="rootscreen">%UCL_PROMPT_ROOT% osg-configure -c</pre>
   * *If you are configuring any other type of node,* edit the value of =SiteName= in your =/etc/gratia/%RED%PROBE-NAME%ENDCOLOR%/ProbeConfig= to match the resource name in OIM corresponding to your host.

---+++ Did the site name change?
Was the site previously reporting data, but the site name (not host name, but site name) changed? When the site name changes, you need to ask the Gratia operations team to update the name of your site at the Gratia collector. To do this:

   1. Open a ticket at [[https://ticket.grid.iu.edu/goc/submit][the GOC ticket web page]]
   1. Under "Optional Details", select "Software or Service"
   1. After you do, another popup will appear. Select "Gratia (Collector Issue)"
   1. Type a friendly email that asks the Gratia team to change your site name at the collector. Make sure to tell them the old name and the new name. 

---+++ Is a site reporting data?

You can see if the OSG Gratia Server is getting data from a site by going to [[http://gratiaweb.grid.iu.edu/gratia/bysite/][GratiaWeb]]:
   
   1. Specify the site name in Facility under Data Filter.
   1. Click "Refine".

---+++ Not collecting HTCondor accounting data

HTCondor must be configured to put information about each job into a special directory. Gratia will read and remove the files in order to collect the accounting information. If left unconfigured, Gratia will not publish accounting information about jobs. 

The configuration variable is called =PER_JOB_HISTORY_DIR=. If you install the OSG RPM for HTCondor, the Gratia probe will extend its configuration by adding a file to =/etc/condor/config.d=, and will set this variable to =/var/lib/gratia/data=. If you are using a different installation method, you will need to set the variable yourself.

Either way, you can check if it's set by using =condor_config_val=, like this:

<pre class="screen">
%UCL_PROMPT% condor_config_val -v PER_JOB_HISTORY_DIR
PER_JOB_HISTORY_DIR: /var/lib/gratia/data
  Defined in '/etc/condor/config.d/99_gratia.conf', line 5.
</pre>

*If the above command returns =Not defined: PER_JOB_HISTORY_DIR=,* you will need to set it and report any old HTCondor data using the following commands:

   1. Set =PER_JOB_HISTORY_DIR = /var/lib/gratia/data= in any file in =/etc/condor/config.d/=.
   1. Restart condor so that your configuration changes take effect (=condor_reconfigure= is insufficient in this case):\
   <pre class="rootscreen">%UCL_PROMPT_ROOT% condor_restart</pre>
   1. Turn off the =gratia-probes-cron= service:
      * On EL6:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% service gratia-probes-cron stop</pre>
      * On EL7:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% systemctl stop gratia-probes-cron</pre>
   1. Report the old HTCondor data:
      * *If you know the time period of the missing data*, run the following command, specifying start and end times in =YYYY-MM-DD= format:\
<pre class="rootscreen">%UCL_PROMPT_ROOT% /usr/share/gratia/condor/condor_meter --history --start-time="&lt;START DATE&gt;</span>" --end-time="&lt;END DATE&gt;</span>" --verbose</pre>
      * *If you do not know the time period of missing data,* run the following command:\
   <pre class="rootscreen">%UCL_PROMPT_ROOT% /usr/share/gratia/condor/condor_meter --history --verbose</pre>
   1. Not much is printed to the screen, but you can see progress in the [[Documentation.Release3/InstallGratia_DRAFT#FilesAndDirs][Gratia log file]].
   1. Start the =gratia-probes-cron= service:
      * On EL6:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% service gratia-probes-cron start</pre>
      * On EL7:\
      <pre class="rootscreen">%UCL_PROMPT_ROOT% systemctl start gratia-probes-cron</pre>

%NOTE% HTCondor rotates history files, so you can only report what HTCondor has kept. Controlling the HTCondor history is documented in the [[http://research.cs.wisc.edu/htcondor/manual/v8.4/4_5Logging_in.html#51346][HTCondor manual]]. In particular, see the options for [[http://research.cs.wisc.edu/htcondor/manual/v8.4/3_3Configuration.html#20361][MAX_HISTORY_LOG]] and [[http://research.cs.wisc.edu/htcondor/manual/v8.4/3_3Configuration.html#20366][MAX_HISTORY_ROTATIONS]].

---+++ Gratia log files: bad Gratia hostname

This is an example problem where the configuration was bad: there was an incorrect hostname for the Gratia server. You can check if this problem occurred in the past month with the following command:

<pre class="rootscreen">grep socket.gaierror /var/log/gratia/`date +%Y-%m`*.log</pre>

---++++ Recovering from bad Gratia hostname

If you accidentally had a bad Gratia hostname, you probably want to recover your Gratia data. This can be done, though it's not simple. There are a few things you need to do. But first, you need to understand exactly where Gratia stores files. 

When a Gratia extracts accounting information, it creates one file per record and stores it in a directory. The directory is a long name that contains the type of the probe (such as =condor=), the name of the host you're running on, and the name of the Gratia host you're sending the information to. For simplicity, lets call that name _probe-records_, but you'll see what it really looks like below. Within this directory, you'll see some subdirectories:

| * Directory * | *Purpose* |
| /var/lib/gratia/tmp/gratiafiles/%RED%probe-records%ENDCOLOR%/outbox | The usual location for the accounting records |
| /var/lib/gratia/tmp/gratiafiles/%RED%probe-records%ENDCOLOR%/staged/store | An overflow location when there are problems |

When you recover old records, you need to:
   1. Before trying to transfer any old records, check if they are more than three months old. If they are, the server will not accept them. This is a policy that is enforced strictly by the admins.
   1. Move files from the outbox of the incorrect _probe-records_ directory into the outbox of the correctly named _probe-records_ directory.
   1. Move tarred and compressed files from the staged/store of the incorrect _probe-records_ directory into the staged/store of the correctly named _probe-records_ directory. Then you uncompress them and remove the compressed version.

In the examples below, the hostname for gratia was "accidentally" spelled backwards. Instead of =gratia-osg-itb.opensciencegrid.org=, it was =aitarg-osg-itb.opensciencegrid.org=. 

---+++++ Correct the hostname
First you need to fix the hostname. For a CE, you can edit =/etc/osg/config.d/30-gratia.ini= and rerun =osg-configure -c=. In other installations, you have to edit the appropriate =ProbeConfig= file. 

---+++++ Run one job

Next, submit a job via HTCondor-CE to your batch system, then run the appropriate Gratia probe. This will create the properly named directories in =/var/lib/gratia/tmp/gratiafiles/=:

<ol>
   <li>
      <p>Submit the job:</p>
      <pre class="screen">%UCL_PROMPT% condor_ce_trace -d `hostname`</pre>
   </li>
   <li>
      <p>Run the Gratia probe for your batch system manually:</p>
      %TABLE{sort="off"}%
      | *If your batch system is...* | *Then run the following command...* |
      | HTCondor | =/usr/share/gratia/condor/condor_meter= |
      | Slurm | =/usr/share/gratia/slurm/slurm_meter= |
      | PBS/Torque | =/usr/share/gratia/pbs-lsf/pbs-lsf_meter.cron.sh= |
      | LSF | =/usr/share/gratia/pbs-lsf/pbs-lsf_meter.cron.sh= |
      | SGE| =/usr/share/gratia/sge/sge_meter.cron.sh= |
   </li>
</ol>

---+++++ Restore the individual Gratia records
First, find the Gratia records that can be easily uploaded. They are located in a a directory with an unwieldly name that includes your hostname and the incorrect name of the Gratia host. You can see the directory name in the Gratia log: the misspelled name is noted in red below, but _it will be different on your computer_. 

<pre class="file">
%UCL_PROMPT% less /var/log/gratia/2012-04-06
...
16:04:29 CDT Gratia: Response indicates failure, the following files will not be deleted:
16:04:29 CDT Gratia:    /var/lib/gratia/tmp/gratiafiles/
    subdir.condor_fermicloud084.fnal.gov_%RED%aitarg%ENDCOLOR%-osg-itb.opensciencegrid.org_80/
    outbox/r.916.condor_fermicloud084.fnal.gov_aitarg-osg-itb.opensciencegrid.org_80.gratia.xml__JDlHbNb918
</pre>

(The filename was wrapped for legibility.)

You can simply copy these to the correct directory. Wait for the Gratia cron job to run, or force it to run.

<pre class="rootscreen">
%UCL_PROMPT_ROOT% cd /var/lib/gratia/tmp/gratiafiles/subdir.condor_fermicloud084.fnal.gov_%RED%aitarg%ENDCOLOR%-osg-itb.opensciencegrid.org_80/outbox/.
%UCL_PROMPT_ROOT% mv * /var/lib/gratia/tmp/gratiafiles/subdir.condor_fermicloud084.fnal.gov_%RED%gratia%ENDCOLOR%-osg-itb.opensciencegrid.org_80/outbox/.
</pre>

---+++++ Restore compressed Gratia records
If this has been a persistent problem, you might have many records. After a while, they are put into a compressed files in another directory. You can move those files, then uncompress them. This is a long name: note that the path ends in "staged/store" instead of "outbox" as above:

<pre class="rootscreen">
%RED%# Find the old files%ENDCOLOR%
%UCL_PROMPT_ROOT% cd /var/lib/gratia/tmp/gratiafiles/subdir.condor_fermicloud084.fnal.gov_%RED%aitarg%ENDCOLOR%-osg-itb.opensciencegrid.org_80/staged/store

%RED%# Move them to the correct directory%ENDCOLOR%
%UCL_PROMPT_ROOT% mv tz* /var/lib/gratia/tmp/gratiafiles/subdir.condor_fermicloud084.fnal.gov_%RED%gratia%ENDCOLOR%-osg-itb.opensciencegrid.org_80/outbox/.
%UCL_PROMPT_ROOT% cd !$

%RED%# For each tz file:%ENDCOLOR%
%UCL_PROMPT_ROOT% tar xf tz.1223.... [name shortened for legibility]
%UCL_PROMPT_ROOT% rm tz.1223....
</pre>

When you've done this, you can re-run the Gratia probe by hand, or wait for it to run via cron.

#OsgSupport
---++ Getting Help

If you are still experiencing issues after using this document, please let us know!

   1. <p>Gather basic Gratia and related information (relevant configuration, problem description, etc.)</p>
   1. <p>Gather system information:</p>\
       <pre class="screen">osg-system-profiler</pre>
   1. <p>Start a support request using [[https://ticket.grid.iu.edu/submit][a web interface]] or by email to [[mailto:goc@opensciencegrid.org][goc@opensciencegrid.org]]</p>
      * Describe issue and expected or desired behavior
      * Include basic Gratia and related information
      * Attach the osg-system-profiler output

#ReferenceSection
---++ Reference

Here are some other Gratia documents that might be helpful:

   * [[Documentation.Release3/GratiaIntroduction_DRAFT][Gratia Probe Introduction]]
   * [[Documentation.Release3/InstallGratia_DRAFT][Installing and Maintaining Gratia Probes]]
   * [[Documentation.Release3/GratiaReference_DRAFT][Gratia Probe Reference]]
   * You can get daily emails with OSG accounting reports in them. Join the [[Accounting.ContactUs][osg-accounting-info]] mailing list. 
   * [[Accounting.WebHome][The Gratia group's web page]]
   * [[Documentation/Release3.NavTechGratia][Gratia's technical documentation index]]
