---+!! *Examples of GIP Configurations*
%DOC_STATUS_TABLE%
%TOC{depth="2"}%


---++ Advertising Subclusters
Subclusters are defined and advertised by creating a Subcluster section.  Multiple subclusters are advertised by defining multiple Subcluster sections with unique names.  Example:  (multiple subclusters)
<pre class="file">
[Subcluster red.unl.edu]
name = red.unl.edu
node_count = 60
ram_mb = 4000
cpu_model = Opteron 275
cpu_vendor = AMD
cpu_speed_mhz = 2200
cpus_per_node = 2
cores_per_node = 4
inbound_network = FALSE
outbound_network = TRUE

[Subcluster Dell Nodes]
name = Dell Nodes
node_count = 53
ram_mb = 4110
cpu_model = Dual-Core AMD Opteron(tm) Processor 2216
cpu_vendor = AMD
cpu_speed_mhz = 2400
cpus_per_node = 2
cores_per_node = 4
inbound_network = FALSE
outbound_network = TRUE

[Subcluster SUN Nodes]
name = SUN Nodes
node_count = 79
ram_mb = 16417
cpu_model = Quad-Core AMD Opteron(tm) Processor 2354
cpu_vendor = AMD
cpu_speed_mhz = 2211
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
</pre>

---++ Advertising a classic SE only
Notice that the !GIP Section is not in this example.  The classic storage element (SE) is advertised by default so there is no need for any options enabling it.  All information about the classic SE is derived from the !Storage section.  The !Subcluster section defines the one subcluster for this example.  
<pre class="file">
[Storage]
grid_dir = /usr/local/osg/wn_client/v1.0.0
app_dir = /export/data/app
data_dir = /export/data/data
worker_node_temp = /tmp
site_read = %(unavailable)s
site_write = %(unavailable)s
</pre>

If you want to disable the advertising of the Classic SE, then create the GIP section and set advertise_gsiftp = False.
<pre class="file">
[GIP]
advertise_gsiftp = False
</pre>

---++ Advertising a classic SE and a 1.9 dCache SE
For this example we set <verbatim>se_available = %(enable)s</verbatim> in the !Storage section since we are advertising a dCache 1.9 SE.  A requirement in this example was to suppress the advertising of dcache doors.  We do this by setting <verbatim>advertise_accesspoints = False</verbatim> in the GIP section.  The dCache SE is defined in the SE dCache section
<pre class="file">
[Storage]
grid_dir = /usr/local/osg/wn_client/v1.0.0
app_dir = /export/data/app
data_dir = /export/data/data
worker_node_temp = /tmp
site_read = %(unavailable)s
site_write = %(unavailable)s
default_se = cmssrm.fnal.gov

[GIP]
advertise_accesspoints = False

[SE dCache]
enabled=True
name = cmssrm.fnal.gov
srm_endpoint = httpg://cmssrm.fnal.gov:8443/srm/managerv2
provider_implementation = dcache19
implementation = dcache
version = 1.9.0-15p6
default_path = /
infoprovider_endpoint = http://cmsdcam.fnal.gov:2288/info
spaces = flushPools,ResilientPools,LFSOnlyPools,ReadOnlyPools,stagePools
space_stagePools_vos = cms,mis
space_ReadOnlyPools_vos = cms,mis
space_LFSOnlyPools_vos = cms,mis
space_ResilientPools_vos = cms,mis
space_flushPools_vos = cms,mis
</pre>

---++ Advertising a classic SE, a 1.8 dCache SE, a Bestman SE
In this example Nebraska is advertising three different types of SE's.  The dCache and Bestaman SE's are defined by creating an SE section for each.  The !provider_implementation option in the !SE sections define the type of SE advertised.  Since the dCache version is 1.8, addition steps had to be taken that are defined in the [[https://twiki.grid.iu.edu/twiki/bin/view/InformationServices/DcacheGip][dCache Provider for the GIP ]] page.
<pre class="file">
[Storage]
default_se = srm.unl.edu
data_dir = /opt/osg/data
app_dir = /opt/osg/app
grid_dir = /opt/osg/osg-wn-source
site_write = srm://srm.unl.edu:8443/pnfs/unl.edu/data4
worker_node_temp = /scratch
site_read = dcap://srm.unl.edu/pnfs/unl.edu/data4

[SE Hadoop]
name = T2_Nebraska_Hadoop
enabled = True
srm_endpoint = httpg://dcache07.unl.edu:8443/srm/v2/server
provider_implementation = bestman
implementation = bestman
version = 2.2.1.2.e1
default_path = /mnt/hadoop/user/VONAME
use_df = True

[SE dCache]
name = T2_Nebraska_Storage
enabled = True
srm_endpoint = httpg://srm.unl.edu:8443/srm/managerv2
provider_implementation = dcache
implementation = dcache
version = 1.8.0-15p6
default_path = /pnfs/unl.edu/data4/VONAME
</pre>

---++ *Comments*
%COMMENT{type="tableappend"}%


<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = AnthonyTiradani

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Trash/Trash/Integration|Operations|Tier3)
   * Local DOC_AREA       = ComputeElement

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Knowledge
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %NO%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = BrianBockelman
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %IN_PROGRESS%


############################################################################################################
-->
